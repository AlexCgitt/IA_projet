{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude   latitude              clc_quartier             clc_secteur  \\\n",
      "0   3.293264  49.840500  Quartier du Centre-Ville             Quai Gayant   \n",
      "1   3.273380  49.861409    Quartier du Vermandois              Stade Cepy   \n",
      "2   3.289068  49.844513  Quartier du Centre-Ville   Rue Villebois Mareuil   \n",
      "3   3.302387  49.861778      Quartier de l'Europe  Square des Marronniers   \n",
      "4   3.304047  49.858446      Quartier de l'Europe           Avenue Buffon   \n",
      "\n",
      "   haut_tot  haut_tronc  tronc_diam fk_arb_etat fk_stadedev     fk_port  \\\n",
      "0       6.0         2.0        37.0    EN PLACE       Jeune  semi libre   \n",
      "1      13.0         1.0       160.0    EN PLACE      Adulte  semi libre   \n",
      "2      12.0         3.0       116.0    REMPLACÉ      Adulte  semi libre   \n",
      "3      16.0         3.0       150.0    EN PLACE      Adulte  semi libre   \n",
      "4       5.0         2.0       170.0    Essouché      Adulte      réduit   \n",
      "\n",
      "  fk_pied fk_situation fk_revetement  age_estim  fk_prec_estim  clc_nbr_diag  \\\n",
      "0   gazon   Alignement           Non       15.0            5.0           0.0   \n",
      "1   gazon       Groupe           Non       50.0           10.0           0.0   \n",
      "2   gazon   Alignement           Non       30.0           10.0           0.0   \n",
      "3   gazon       Groupe           Non       50.0            2.0           0.0   \n",
      "4   gazon        Isolé           Non       40.0            2.0           0.0   \n",
      "\n",
      "  fk_nomtech villeca feuillage remarquable  \n",
      "0     QUERUB   VILLE   Feuillu         Non  \n",
      "1  PINNIGnig   VILLE  Conifère         Non  \n",
      "2     ACEPSE   VILLE   Feuillu         Non  \n",
      "3     ACEPLA   VILLE   Feuillu         Non  \n",
      "4     SALBAB   VILLE   Feuillu         Non  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#recupere les données de Data_Arbre.csv\n",
    "data = pd.read_csv(\"Data_Arbre.csv\")\n",
    "\n",
    "print(data.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age_estim\n",
      "0       15.0\n",
      "1       50.0\n",
      "2       30.0\n",
      "3       50.0\n",
      "4       40.0\n"
     ]
    }
   ],
   "source": [
    "#sépare les données en deux dataframes, un pour les X et un pour les Y, les X sont la colonne age_estim, et les Y sont les colonnes tronc_diam  + haut_tronc + clc_nbr_diag \n",
    "Y = data[['age_estim']]\n",
    "\n",
    "X = data[['tronc_diam','haut_tronc', 'haut_tot', 'clc_nbr_diag', 'fk_stadedev', 'fk_nomtech']]\n",
    "\n",
    "print(Y.head(5))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_4388\\1827100589.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['fk_stadedev'] = encoder.fit_transform(X[['fk_stadedev']])\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_4388\\1827100589.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['fk_nomtech'] = label.fit_transform(X[['fk_nomtech']])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "#encoder permet de transformer les valeurs de la colonne en valeurs numériques (ordonnees)\n",
    "label = LabelEncoder()\n",
    "#label permet de transformer les valeurs de la colonne en valeurs numériques\n",
    "\n",
    "\n",
    "X['fk_stadedev'] = encoder.fit_transform(X[['fk_stadedev']])\n",
    "X['fk_nomtech'] = label.fit_transform(X[['fk_nomtech']])\n",
    "# X['feuillage'] = encoder.fit_transform(X[['feuillage']])\n",
    "# print(X['feuillage'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoder permet de transformer les valeurs de la colonne en valeurs numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7409, 6) (7409, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_X = StandardScaler()\n",
    "scaler_Y = StandardScaler()\n",
    "\n",
    "X = scaler_X.fit_transform(X)\n",
    "Y = scaler_Y.fit_transform(Y)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaler réduit remarquablement les scores RMSE et MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices des lignes dans X_test: [7092 1544 2431 ... 4139 6203 4393]\n",
      "Indices des lignes dans X: [   0    1    2 ... 7406 7407 7408]\n",
      "438     30.0\n",
      "3320    35.0\n",
      "3937    40.0\n",
      "434     30.0\n",
      "751     50.0\n",
      "1488    50.0\n",
      "1593    50.0\n",
      "4139    60.0\n",
      "6203    30.0\n",
      "4393    30.0\n",
      "Name: age_estim, dtype: float64\n",
      "[[ 0.12165495  1.21102921  1.02314578 -0.27980404 -0.56224657  1.5375964 ]\n",
      " [-0.33570685 -0.46555    -0.59694528 -0.27980404 -0.56224657 -1.0182212 ]\n",
      " [ 0.9347426  -1.02440973  0.53711846 -0.27980404 -0.56224657 -0.95878358]\n",
      " ...\n",
      " [-0.08161696  0.09330974  1.83319131 -0.27980404 -0.56224657 -1.28569048]\n",
      " [ 1.44292238 -0.74497987 -0.59694528 -0.27980404 -0.56224657 -0.78047072]\n",
      " [ 0.34186619 -0.46555    -0.43493618 -0.27980404 -0.56224657  0.86892319]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "X_train, X_test, Y_train, Y_test, indices_train, indices_test = train_test_split(X, Y, indices, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Indices des lignes dans X_test:\", indices_test)\n",
    "print(\"Indices des lignes dans X:\", indices)\n",
    "\n",
    "data_test = data.iloc[indices_test]\n",
    "\n",
    "data_test.to_json('Data_Arbre_test.json', orient='records')\n",
    "\n",
    "print(data_test[\"age_estim\"].tail(10))\n",
    "\n",
    "print(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search pour RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mbell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params : {'max_depth': 15, 'max_samples': 0.8, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# forest = RandomForestRegressor()\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [200,300,400],\n",
    "#     'max_depth' : [10,15,20],\n",
    "#     'min_samples_split': [2,3],\n",
    "#     'min_samples_leaf': [1, 2],\n",
    "#     'max_samples': [0.6, 0.7, 0.8,0.9, 1]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=forest, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "# best_model = grid_search.best_estimator_\n",
    "# print('best params :', grid_search.best_params_)\n",
    "\n",
    "\n",
    "# # best params : {'max_depth': 15, 'max_samples': 0.8, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
    "# # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score du modèle de régression linéaire : 0.8181589076193863\n",
      "RMSE du modèle de régression linéaire : 0.4260740869260982\n",
      "MAE du modèle de régression linéaire : 0.25305225751731947\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_forest = RandomForestRegressor(max_depth= 15, min_samples_leaf= 1, min_samples_split= 2, \n",
    "                                         n_estimators= 400, max_samples=0.8, max_features=\"log2\", random_state=42)\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "r2_score_forest = r2_score(Y_test, Y_pred)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "\n",
    "cross_val_score_forest = cross_val_score(random_forest, X_test, Y_test, cv=5).mean()\n",
    "\n",
    "print(\"R2 score du modèle de régression linéaire :\", r2_score_forest)\n",
    "print(\"RMSE du modèle de régression linéaire :\", rmse)\n",
    "print(\"MAE du modèle de régression linéaire :\", mae)\n",
    "# print(\"Cross val score du modèle de régression linéaire :\", cross_val_score_forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CART : Classification And Regression Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search pour CART : \n",
    "Le DecisionTreeRegressor est une implémentation de l'algorithme CART (Classification And Regression Tree) pour les problèmes de régression\n",
    "C'est un arbre qui va diviser l'ensemble des données, en sous-ensemble, et le refaire plusieurs fois\n",
    "\n",
    "Au début, la racine contient l'ensemble des données\n",
    "Pour chaque caractéristique, l'algorithme cherche le meilleur point de division (seuil) qui divise les données en deux sous-ensembles de manière à réduire au maximum l'erreur de régression.\n",
    "L'erreur de régression est souvent mesurée par le MSE (Mean Squared Error) ou le MAE (Mean Absolute Error). Le but est de minimiser cette erreur dans les sous-ensembles qui sont créés.\n",
    "\n",
    "Quand on a trouvé le meilleur point de division, on divise les données en 2 sous-ensemble à partir de ce point.\n",
    "\n",
    "On répète la même méthode sur chaque sous-ensemble\n",
    "\n",
    "Chaque noeud de l'arbre représente une condition sur une caractéristique et un seuil, et chaque feuille représente une prédiction de la valeur cible.\n",
    "\n",
    "On s'arrête quand on a atteint une des conditions d'arrêt (profondeure maximale, nombre d'échantillons dans un noeud inférieur à un seuil minimum, si on ne réduit plus l'erreur de régression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explication des hyperparametres du grid search :\n",
    "\n",
    "max_depth : profondeur maximale de l'arbre, peut réduire le risque de surapprentissage.\n",
    "min_samples_split : Le nombre minimum d'échantillons requis pour diviser un noeud interne.\n",
    "min_samples_leaf : nombre minimum d'échantillons requis pour être à un noeud feuille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 196 candidates, totalling 980 fits\n",
      "best params : {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "# #grid search pour trouver les meilleurs paramètres de decision tree regressor\n",
    "# param_grid = {\n",
    "#     'max_depth' : [7,8,9,10,11,12,13],\n",
    "#     'min_samples_split': [2,3,4,5,6,7,8],\n",
    "#     'min_samples_leaf': [1, 2, 3, 4]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=DecisionTreeRegressor(), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# print('best params :', grid_search.best_params_)\n",
    "# #best params : {'max_depth': 10, 'min_samples_leaf': 3, 'min_samples_split': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score du modèle de régression linéaire : 0.7535262261307794\n",
      "RMSE du modèle de régression linéaire : 0.49604886874262627\n",
      "MAE du modèle de régression linéaire : 0.29687267492271835\n",
      "Cross val score du modèle de régression linéaire : 0.6440786756106726\n"
     ]
    }
   ],
   "source": [
    "best_model_found = DecisionTreeRegressor(max_depth= 10, min_samples_leaf= 3, min_samples_split= 4)\n",
    "\n",
    "tree = best_model_found\n",
    "tree.fit(X_train, Y_train)\n",
    "Y_pred = tree.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "r2_scoreee = r2_score(Y_test, Y_pred)\n",
    "\n",
    "cross_val_score_tree = cross_val_score(tree, X_test, Y_test, cv=5).mean()\n",
    "\n",
    "print(\"R2 score du modèle de régression linéaire :\", r2_scoreee)\n",
    "print(\"RMSE du modèle de régression linéaire :\", rmse)\n",
    "print(\"MAE du modèle de régression linéaire :\", mae)\n",
    "print(\"Cross val score du modèle de régression linéaire :\", cross_val_score_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "methode 3 : Réseau de neurones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search pour réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mbell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params : {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# grid search pour trouver les meilleurs paramètres de MLPRegressor\n",
    "# param_grid : dictionnaire contenant les différentes combinaisons de paramètres à tester\n",
    "# 'hidden_layer_sizes' : liste des différentes architectures de couches cachées à tester\n",
    "# 'activation' : liste des différentes fonctions d'activation à tester\n",
    "# 'solver' : liste des différents solveurs à tester\n",
    "# 'alpha' : liste des différents paramètres de régularisation à tester\n",
    "# 'learning_rate' : liste des différents taux d'apprentissage à tester\n",
    "\n",
    "# param_grid={\n",
    "#     'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,100)],\n",
    "#     'activation': ['tanh', 'relu'],\n",
    "#     'solver': ['sgd', 'adam'],\n",
    "#     'alpha': [0.0001, 0.05],\n",
    "#     'learning_rate': ['constant','adaptive'],\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=MLPRegressor(), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# print('best params :', grid_search.best_params_)\n",
    "\n",
    "# #best params : {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (100, 100), 'learning_rate': 'adaptive', 'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1631: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score du modèle de régression linéaire : 0.7614002920266387\n",
      "RMSE du modèle de régression linéaire : 0.4880609489988986\n",
      "MAE du modèle de régression linéaire : 0.32594839593380465\n",
      "Cross val score du modèle de régression linéaire : 0.7009214306870944\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_model_found = MLPRegressor(hidden_layer_sizes=(24, 48), activation='relu', alpha=0.05, learning_rate='adaptive', solver='adam', max_iter=1000)\n",
    "mlp = best_model_found\n",
    "mlp.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = mlp.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "r2_score_mlp = r2_score(Y_test, Y_pred)\n",
    "\n",
    "cross_val_score_mlp = cross_val_score(mlp, X_test, Y_test, cv=5).mean()\n",
    "\n",
    "print(\"R2 score du modèle de régression linéaire :\", r2_score_mlp)\n",
    "print(\"RMSE du modèle de régression linéaire :\", rmse)\n",
    "print(\"MAE du modèle de régression linéaire :\", mae)\n",
    "print(\"Cross val score du modèle de régression linéaire :\", cross_val_score_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 280 candidates, totalling 1400 fits\n",
      "best params : {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 10, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# #grid search pour trouver les meilleurs paramètres de KNeighborsRegressor\n",
    "# param_grid = {\n",
    "#     'n_neighbors': [9,10,11,12,13,14,15],\n",
    "#     'weights': ['uniform', 'distance'],\n",
    "#     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "#     'leaf_size': [10,20,30,40,50]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=KNeighborsRegressor(), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# print('best params :', grid_search.best_params_)\n",
    "\n",
    "# #best params : {'algorithm': 'ball_tree', 'leaf_size': 20, 'n_neighbors': 10, 'weights': 'distance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score du modèle de régression linéaire : 0.7848117216516649\n",
      "RMSE du modèle de régression linéaire : 0.46349858389209364\n",
      "MAE du modèle de régression linéaire : 0.2578538355544143\n",
      "Cross val score du modèle de régression linéaire : 0.7085339410672501\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_model_found = KNeighborsRegressor(n_neighbors=10, weights='distance', algorithm='ball_tree', leaf_size=20)\n",
    "\n",
    "knn = best_model_found\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = knn.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "r2_score_knn = r2_score(Y_test, Y_pred)\n",
    "\n",
    "cross_val_score_knn = cross_val_score(knn, X_test, Y_test, cv=5).mean()\n",
    "\n",
    "print(\"R2 score du modèle de régression linéaire :\", r2_score_knn)\n",
    "print(\"RMSE du modèle de régression linéaire :\", rmse)\n",
    "print(\"MAE du modèle de régression linéaire :\", mae)\n",
    "print(\"Cross val score du modèle de régression linéaire :\", cross_val_score_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele 5 : HistGrandiantBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search pour HistGrandientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mbell\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params : {'learning_rate': 0.1, 'max_depth': 15, 'max_iter': 500, 'max_leaf_nodes': 31}\n"
     ]
    }
   ],
   "source": [
    "# #grid search pour trouver les meilleurs paramètres de HistGradientBoostingRegressor\n",
    "\n",
    "# param_grid = {\n",
    "#     'max_iter': [200,300,400,500],\n",
    "#     'max_leaf_nodes': [31, 41, 51],\n",
    "#     'learning_rate': [0.1, 0.2, 0.3],\n",
    "#     'max_depth': [10, 15, 20]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=HistGradientBoostingRegressor(), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# print('best params :', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score du modèle de régression linéaire : 0.8079655948978623\n",
      "RMSE du modèle de régression linéaire : 0.43785330109940146\n",
      "MAE du modèle de régression linéaire : 0.26822405515355563\n",
      "Cross val score du modèle de régression linéaire : 0.7263892763502553\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hist = HistGradientBoostingRegressor(learning_rate= 0.1, max_depth = 15, max_iter = 300, max_leaf_nodes = 31, random_state=42)\n",
    "hist.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = hist.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "r2_score_hist = r2_score(Y_test, Y_pred)\n",
    "\n",
    "cross_val_score_hist = cross_val_score(hist, X_test, Y_test, cv=5).mean()\n",
    "\n",
    "print(\"R2 score du modèle de régression linéaire :\", r2_score_hist)\n",
    "print(\"RMSE du modèle de régression linéaire :\", rmse)\n",
    "print(\"MAE du modèle de régression linéaire :\", mae)\n",
    "print(\"Cross val score du modèle de régression linéaire :\", cross_val_score_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On met les modèles en .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dict_pickle = {\n",
    "    'ordinal' : encoder,\n",
    "    'label' : label,\n",
    "    'scaler_X' : scaler_X,\n",
    "    'scaler_Y' : scaler_Y,\n",
    "    'RandomForest': random_forest,\n",
    "    'DecisionTree': tree,\n",
    "    'MLP': mlp,\n",
    "    'KNN': knn,\n",
    "    'Hist': hist\n",
    "}\n",
    "\n",
    "# Sauvegarder le modèle dans un fichier .pkl\n",
    "with open('dict.pkl', 'wb') as file:\n",
    "    pickle.dump(dict_pickle, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test d'ouverture de nos fichiers .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score du modèle de régression linéaire : 0.8181589076193863\n",
      "RMSE du modèle de régression linéaire : 0.4260740869260982\n",
      "MAE du modèle de régression linéaire : 0.25305225751731947\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('dict.pkl', 'rb') as file:\n",
    "    pkl_dict = pickle.load(file)\n",
    "\n",
    "\n",
    "model = pkl_dict['RandomForest']\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_test, Y_pred)\n",
    "r2_score_model = r2_score(Y_test, Y_pred)\n",
    "\n",
    "# cross_val_score_hist = cross_val_score(model, X_test, Y_test, cv=5).mean()\n",
    "\n",
    "print(\"R2 score du modèle de régression linéaire :\", r2_score_model)\n",
    "print(\"RMSE du modèle de régression linéaire :\", rmse)\n",
    "print(\"MAE du modèle de régression linéaire :\", mae)\n",
    "# print(\"Cross val score du modèle de régression linéaire :\", cross_val_score_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du fichier JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438     30.0\n",
      "3320    35.0\n",
      "3937    40.0\n",
      "434     30.0\n",
      "751     50.0\n",
      "1488    50.0\n",
      "1593    50.0\n",
      "4139    60.0\n",
      "6203    30.0\n",
      "4393    30.0\n",
      "Name: age_estim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# data_test = data.iloc[indices_test]\n",
    "\n",
    "# data_test.to_json('Data_Arbre_test.json', orient='records')\n",
    "\n",
    "# print(data_test[\"age_estim\"].tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTS DE MON SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n",
      "StandardScaler()\n",
      "RandomForestRegressor(max_depth=15, max_features='log2', max_samples=0.8,\n",
      "                      n_estimators=400, random_state=42)\n",
      "OrdinalEncoder()\n",
      "LabelEncoder()\n",
      "[[ 1.18379275  0.13637661 -0.55988451 -0.29322258  1.53691341  1.06471625]\n",
      " [-0.44619807 -0.3225397  -0.55988451 -0.29322258 -1.01116019 -0.59746587]\n",
      " [-0.98952835  0.95222783 -0.55988451 -0.29322258 -0.96168303  0.56606162]\n",
      " ...\n",
      " [ 0.0971322  -0.06758619 -0.55988451 -0.29322258 -1.30802314  1.89580731]\n",
      " [-0.71786321  1.46213485 -0.55988451 -0.29322258 -0.73903583 -0.59746587]\n",
      " [-0.44619807  0.35733632 -0.55988451 -0.29322258  0.77001747 -0.43124765]]\n",
      "r2_score =  0.27214094856223514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_4388\\2831851170.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['fk_stadedev'] = pkl_dict_load['ordinal'].fit_transform(X[['fk_stadedev']])\n",
      "C:\\Users\\alexm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_4388\\2831851170.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['fk_nomtech'] = pkl_dict_load['label'].fit_transform(X[['fk_nomtech']])\n"
     ]
    }
   ],
   "source": [
    "with open('dict.pkl', 'rb') as file:\n",
    "    pkl_dict_load = pickle.load(file)\n",
    "\n",
    "scaler_X = pkl_dict_load['scaler_X']\n",
    "scaler_Y = pkl_dict_load['scaler_Y']\n",
    "model = pkl_dict_load['RandomForest']\n",
    "ordinal = pkl_dict_load['ordinal']\n",
    "label = pkl_dict_load['label']\n",
    "\n",
    "print(scaler_X)\n",
    "print(scaler_Y)\n",
    "print(model)\n",
    "print(ordinal)\n",
    "print(label)\n",
    "\n",
    "X = data_test[['haut_tronc','tronc_diam','fk_stadedev','clc_nbr_diag','fk_nomtech','haut_tot']]\n",
    "\n",
    "X['fk_stadedev'] = pkl_dict_load['ordinal'].fit_transform(X[['fk_stadedev']])\n",
    "X['fk_nomtech'] = pkl_dict_load['label'].fit_transform(X[['fk_nomtech']])\n",
    "y_test = data_test['age_estim']\n",
    "\n",
    "X = pkl_dict_load['scaler_X'].fit_transform(X)\n",
    "\n",
    "print(X)\n",
    "\n",
    "\n",
    "pred = pkl_dict_load['RandomForest'].predict(X) \n",
    "\n",
    "pred = pred.reshape(-1, 1)\n",
    "\n",
    "# y_test_scaled = scaler_Y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "pred = pkl_dict_load['scaler_Y'].inverse_transform(pred)\n",
    "\n",
    "r2_score_model = r2_score(y_test, pred)\n",
    "print(\"r2_score = \", r2_score_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CART from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
